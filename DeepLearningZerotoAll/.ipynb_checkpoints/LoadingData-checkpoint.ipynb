{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "#모델 초기화\n",
    "W = torch.zeros([3,1], requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "#optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 hypothesis: tensor([0., 0., 0., 0., 0.]), Cost: 29661.800781\n",
      "Epoch    1/100 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]), Cost: 9298.520508\n",
      "Epoch    2/100 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]), Cost: 2915.712402\n",
      "Epoch    3/100 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]), Cost: 915.040527\n",
      "Epoch    4/100 hypothesis: tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]), Cost: 287.936096\n",
      "Epoch    5/100 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]), Cost: 91.371063\n",
      "Epoch    6/100 hypothesis: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]), Cost: 29.758249\n",
      "Epoch    7/100 hypothesis: tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]), Cost: 10.445267\n",
      "Epoch    8/100 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]), Cost: 4.391237\n",
      "Epoch    9/100 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]), Cost: 2.493121\n",
      "Epoch   10/100 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]), Cost: 1.897688\n",
      "Epoch   11/100 hypothesis: tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]), Cost: 1.710552\n",
      "Epoch   12/100 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]), Cost: 1.651416\n",
      "Epoch   13/100 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]), Cost: 1.632369\n",
      "Epoch   14/100 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]), Cost: 1.625924\n",
      "Epoch   15/100 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]), Cost: 1.623420\n",
      "Epoch   16/100 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]), Cost: 1.622152\n",
      "Epoch   17/100 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]), Cost: 1.621262\n",
      "Epoch   18/100 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]), Cost: 1.620501\n",
      "Epoch   19/100 hypothesis: tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]), Cost: 1.619757\n",
      "Epoch   20/100 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]), Cost: 1.619046\n",
      "Epoch   21/100 hypothesis: tensor([152.8022, 183.6741, 180.9683, 197.0706, 140.1009]), Cost: 1.618348\n",
      "Epoch   22/100 hypothesis: tensor([152.8021, 183.6749, 180.9686, 197.0709, 140.1017]), Cost: 1.617638\n",
      "Epoch   23/100 hypothesis: tensor([152.8019, 183.6754, 180.9687, 197.0710, 140.1022]), Cost: 1.616936\n",
      "Epoch   24/100 hypothesis: tensor([152.8016, 183.6758, 180.9687, 197.0710, 140.1027]), Cost: 1.616214\n",
      "Epoch   25/100 hypothesis: tensor([152.8012, 183.6762, 180.9686, 197.0710, 140.1032]), Cost: 1.615513\n",
      "Epoch   26/100 hypothesis: tensor([152.8008, 183.6765, 180.9686, 197.0710, 140.1037]), Cost: 1.614808\n",
      "Epoch   27/100 hypothesis: tensor([152.8004, 183.6768, 180.9684, 197.0709, 140.1041]), Cost: 1.614109\n",
      "Epoch   28/100 hypothesis: tensor([152.8000, 183.6772, 180.9683, 197.0708, 140.1045]), Cost: 1.613405\n",
      "Epoch   29/100 hypothesis: tensor([152.7995, 183.6775, 180.9682, 197.0706, 140.1049]), Cost: 1.612695\n",
      "Epoch   30/100 hypothesis: tensor([152.7991, 183.6778, 180.9681, 197.0705, 140.1053]), Cost: 1.611981\n",
      "Epoch   31/100 hypothesis: tensor([152.7987, 183.6781, 180.9679, 197.0704, 140.1057]), Cost: 1.611289\n",
      "Epoch   32/100 hypothesis: tensor([152.7982, 183.6784, 180.9678, 197.0703, 140.1061]), Cost: 1.610577\n",
      "Epoch   33/100 hypothesis: tensor([152.7978, 183.6787, 180.9677, 197.0702, 140.1065]), Cost: 1.609871\n",
      "Epoch   34/100 hypothesis: tensor([152.7974, 183.6790, 180.9675, 197.0701, 140.1069]), Cost: 1.609167\n",
      "Epoch   35/100 hypothesis: tensor([152.7970, 183.6793, 180.9674, 197.0700, 140.1073]), Cost: 1.608482\n",
      "Epoch   36/100 hypothesis: tensor([152.7965, 183.6796, 180.9673, 197.0699, 140.1078]), Cost: 1.607761\n",
      "Epoch   37/100 hypothesis: tensor([152.7961, 183.6799, 180.9672, 197.0698, 140.1082]), Cost: 1.607080\n",
      "Epoch   38/100 hypothesis: tensor([152.7957, 183.6802, 180.9670, 197.0697, 140.1086]), Cost: 1.606368\n",
      "Epoch   39/100 hypothesis: tensor([152.7952, 183.6805, 180.9669, 197.0695, 140.1090]), Cost: 1.605665\n",
      "Epoch   40/100 hypothesis: tensor([152.7948, 183.6807, 180.9668, 197.0694, 140.1094]), Cost: 1.604975\n",
      "Epoch   41/100 hypothesis: tensor([152.7944, 183.6810, 180.9666, 197.0693, 140.1098]), Cost: 1.604280\n",
      "Epoch   42/100 hypothesis: tensor([152.7939, 183.6814, 180.9665, 197.0692, 140.1102]), Cost: 1.603572\n",
      "Epoch   43/100 hypothesis: tensor([152.7935, 183.6817, 180.9664, 197.0691, 140.1106]), Cost: 1.602870\n",
      "Epoch   44/100 hypothesis: tensor([152.7931, 183.6819, 180.9663, 197.0690, 140.1110]), Cost: 1.602174\n",
      "Epoch   45/100 hypothesis: tensor([152.7926, 183.6822, 180.9661, 197.0688, 140.1114]), Cost: 1.601473\n",
      "Epoch   46/100 hypothesis: tensor([152.7922, 183.6825, 180.9660, 197.0687, 140.1118]), Cost: 1.600761\n",
      "Epoch   47/100 hypothesis: tensor([152.7918, 183.6828, 180.9659, 197.0686, 140.1122]), Cost: 1.600087\n",
      "Epoch   48/100 hypothesis: tensor([152.7913, 183.6831, 180.9657, 197.0685, 140.1126]), Cost: 1.599370\n",
      "Epoch   49/100 hypothesis: tensor([152.7909, 183.6834, 180.9656, 197.0684, 140.1130]), Cost: 1.598685\n",
      "Epoch   50/100 hypothesis: tensor([152.7905, 183.6837, 180.9655, 197.0683, 140.1134]), Cost: 1.597979\n",
      "Epoch   51/100 hypothesis: tensor([152.7901, 183.6840, 180.9653, 197.0682, 140.1138]), Cost: 1.597292\n",
      "Epoch   52/100 hypothesis: tensor([152.7896, 183.6843, 180.9652, 197.0681, 140.1143]), Cost: 1.596590\n",
      "Epoch   53/100 hypothesis: tensor([152.7892, 183.6846, 180.9651, 197.0679, 140.1147]), Cost: 1.595898\n",
      "Epoch   54/100 hypothesis: tensor([152.7888, 183.6849, 180.9650, 197.0678, 140.1151]), Cost: 1.595211\n",
      "Epoch   55/100 hypothesis: tensor([152.7883, 183.6852, 180.9648, 197.0677, 140.1155]), Cost: 1.594514\n",
      "Epoch   56/100 hypothesis: tensor([152.7879, 183.6855, 180.9647, 197.0676, 140.1159]), Cost: 1.593807\n",
      "Epoch   57/100 hypothesis: tensor([152.7875, 183.6858, 180.9646, 197.0675, 140.1163]), Cost: 1.593116\n",
      "Epoch   58/100 hypothesis: tensor([152.7870, 183.6861, 180.9644, 197.0674, 140.1167]), Cost: 1.592426\n",
      "Epoch   59/100 hypothesis: tensor([152.7866, 183.6864, 180.9643, 197.0673, 140.1171]), Cost: 1.591729\n",
      "Epoch   60/100 hypothesis: tensor([152.7862, 183.6867, 180.9642, 197.0672, 140.1175]), Cost: 1.591051\n",
      "Epoch   61/100 hypothesis: tensor([152.7858, 183.6870, 180.9641, 197.0671, 140.1179]), Cost: 1.590355\n",
      "Epoch   62/100 hypothesis: tensor([152.7853, 183.6873, 180.9639, 197.0669, 140.1183]), Cost: 1.589660\n",
      "Epoch   63/100 hypothesis: tensor([152.7849, 183.6876, 180.9638, 197.0668, 140.1187]), Cost: 1.588956\n",
      "Epoch   64/100 hypothesis: tensor([152.7845, 183.6879, 180.9637, 197.0667, 140.1191]), Cost: 1.588267\n",
      "Epoch   65/100 hypothesis: tensor([152.7840, 183.6882, 180.9635, 197.0666, 140.1195]), Cost: 1.587576\n",
      "Epoch   66/100 hypothesis: tensor([152.7836, 183.6885, 180.9634, 197.0665, 140.1199]), Cost: 1.586890\n",
      "Epoch   67/100 hypothesis: tensor([152.7832, 183.6888, 180.9633, 197.0664, 140.1203]), Cost: 1.586201\n",
      "Epoch   68/100 hypothesis: tensor([152.7828, 183.6891, 180.9632, 197.0663, 140.1207]), Cost: 1.585519\n",
      "Epoch   69/100 hypothesis: tensor([152.7823, 183.6893, 180.9630, 197.0662, 140.1211]), Cost: 1.584820\n",
      "Epoch   70/100 hypothesis: tensor([152.7819, 183.6896, 180.9629, 197.0660, 140.1215]), Cost: 1.584131\n",
      "Epoch   71/100 hypothesis: tensor([152.7815, 183.6899, 180.9628, 197.0659, 140.1219]), Cost: 1.583449\n",
      "Epoch   72/100 hypothesis: tensor([152.7811, 183.6902, 180.9626, 197.0658, 140.1223]), Cost: 1.582766\n",
      "Epoch   73/100 hypothesis: tensor([152.7806, 183.6905, 180.9625, 197.0657, 140.1227]), Cost: 1.582072\n",
      "Epoch   74/100 hypothesis: tensor([152.7802, 183.6908, 180.9624, 197.0656, 140.1231]), Cost: 1.581379\n",
      "Epoch   75/100 hypothesis: tensor([152.7798, 183.6911, 180.9622, 197.0655, 140.1236]), Cost: 1.580685\n",
      "Epoch   76/100 hypothesis: tensor([152.7793, 183.6914, 180.9621, 197.0654, 140.1240]), Cost: 1.580014\n",
      "Epoch   77/100 hypothesis: tensor([152.7789, 183.6917, 180.9620, 197.0652, 140.1244]), Cost: 1.579320\n",
      "Epoch   78/100 hypothesis: tensor([152.7785, 183.6920, 180.9619, 197.0652, 140.1248]), Cost: 1.578649\n",
      "Epoch   79/100 hypothesis: tensor([152.7781, 183.6923, 180.9617, 197.0650, 140.1252]), Cost: 1.577945\n",
      "Epoch   80/100 hypothesis: tensor([152.7776, 183.6926, 180.9616, 197.0649, 140.1256]), Cost: 1.577259\n",
      "Epoch   81/100 hypothesis: tensor([152.7772, 183.6929, 180.9615, 197.0648, 140.1260]), Cost: 1.576571\n",
      "Epoch   82/100 hypothesis: tensor([152.7768, 183.6932, 180.9613, 197.0647, 140.1264]), Cost: 1.575898\n",
      "Epoch   83/100 hypothesis: tensor([152.7764, 183.6935, 180.9612, 197.0646, 140.1268]), Cost: 1.575204\n",
      "Epoch   84/100 hypothesis: tensor([152.7759, 183.6938, 180.9611, 197.0645, 140.1272]), Cost: 1.574523\n",
      "Epoch   85/100 hypothesis: tensor([152.7755, 183.6941, 180.9610, 197.0643, 140.1276]), Cost: 1.573825\n",
      "Epoch   86/100 hypothesis: tensor([152.7751, 183.6944, 180.9609, 197.0643, 140.1280]), Cost: 1.573149\n",
      "Epoch   87/100 hypothesis: tensor([152.7747, 183.6946, 180.9607, 197.0641, 140.1284]), Cost: 1.572478\n",
      "Epoch   88/100 hypothesis: tensor([152.7742, 183.6949, 180.9606, 197.0640, 140.1288]), Cost: 1.571791\n",
      "Epoch   89/100 hypothesis: tensor([152.7738, 183.6952, 180.9605, 197.0639, 140.1292]), Cost: 1.571114\n",
      "Epoch   90/100 hypothesis: tensor([152.7734, 183.6955, 180.9603, 197.0638, 140.1296]), Cost: 1.570416\n",
      "Epoch   91/100 hypothesis: tensor([152.7729, 183.6958, 180.9602, 197.0637, 140.1300]), Cost: 1.569741\n",
      "Epoch   92/100 hypothesis: tensor([152.7725, 183.6961, 180.9601, 197.0636, 140.1304]), Cost: 1.569064\n",
      "Epoch   93/100 hypothesis: tensor([152.7721, 183.6964, 180.9600, 197.0635, 140.1308]), Cost: 1.568379\n",
      "Epoch   94/100 hypothesis: tensor([152.7717, 183.6967, 180.9598, 197.0634, 140.1312]), Cost: 1.567695\n",
      "Epoch   95/100 hypothesis: tensor([152.7712, 183.6970, 180.9597, 197.0632, 140.1316]), Cost: 1.567017\n",
      "Epoch   96/100 hypothesis: tensor([152.7708, 183.6973, 180.9596, 197.0632, 140.1320]), Cost: 1.566340\n",
      "Epoch   97/100 hypothesis: tensor([152.7704, 183.6976, 180.9595, 197.0630, 140.1324]), Cost: 1.565659\n",
      "Epoch   98/100 hypothesis: tensor([152.7700, 183.6979, 180.9593, 197.0629, 140.1328]), Cost: 1.564988\n",
      "Epoch   99/100 hypothesis: tensor([152.7695, 183.6982, 180.9592, 197.0628, 140.1332]), Cost: 1.564298\n",
      "Epoch  100/100 hypothesis: tensor([152.7691, 183.6985, 180.9591, 197.0627, 140.1336]), Cost: 1.563628\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    #H(x)계산\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    \n",
    "    #cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    print('Epoch {:4d}/{} hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))\n",
    "    \n",
    "        \n",
    "    #cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Cost: 26829.431641\n",
      "Epoch    1/20 Cost: 8410.263672\n",
      "Epoch    2/20 Cost: 2636.833008\n",
      "Epoch    3/20 Cost: 827.167786\n",
      "Epoch    4/20 Cost: 259.934875\n",
      "Epoch    5/20 Cost: 82.136429\n",
      "Epoch    6/20 Cost: 26.405834\n",
      "Epoch    7/20 Cost: 8.936948\n",
      "Epoch    8/20 Cost: 3.461127\n",
      "Epoch    9/20 Cost: 1.744446\n",
      "Epoch   10/20 Cost: 1.206066\n",
      "Epoch   11/20 Cost: 1.037017\n",
      "Epoch   12/20 Cost: 0.983738\n",
      "Epoch   13/20 Cost: 0.966756\n",
      "Epoch   14/20 Cost: 0.961132\n",
      "Epoch   15/20 Cost: 0.959080\n",
      "Epoch   16/20 Cost: 0.958140\n",
      "Epoch   17/20 Cost: 0.957561\n",
      "Epoch   18/20 Cost: 0.957096\n",
      "Epoch   19/20 Cost: 0.956650\n",
      "Epoch   20/20 Cost: 0.956227\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# 모델 초기화\n",
    "model = MultivariateLinearRegressionModel()\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                      [93, 88, 93],\n",
    "                      [89, 91, 90],\n",
    "                      [96, 98, 100],\n",
    "                      [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [196], [142]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0/20 Batch 1/3 Cost: 1341.129761\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-68c20e44cf87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnb_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#H(x) 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-4ab43a458273>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        #H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        #cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        #cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch: {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(epoch, nb_epochs,\n",
    "                                                               batch_idx+1, len(dataloader),\n",
    "                                                                               cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## slicing 1D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(nums[2:4]) #index 2에서 4전까지 가져와라 앞 포함 뒤 비포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums[2:4] = [8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 8, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing 2D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1, 2, 3, 4], \n",
    "             [5, 6, 7, 8],\n",
    "             [9, 10, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6, 10])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1] #마지막 행 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6, 10])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,1] #마지막 열 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 5,  6,  7],\n",
       "       [ 9, 10, 11]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
